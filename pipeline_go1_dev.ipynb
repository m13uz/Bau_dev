{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "*1. import the image with a red rectangle to get the object  \n",
    "*2. import other png images to use that as a background\n",
    "*3. Crop the region of interest from the img with the target object\n",
    "*4. Write a dataloader that pastes the object of interest on a random background image\n",
    "*5. Add very many transformations to this dataloader - COULD ADD MANY MORE\n",
    "*6. Write up a neural net class for the detection \n",
    "*7. Train the neural net and see how the training goes\n",
    "\n",
    "8. If things go smoothly check the model on other datasets with different inter-class objects.\n",
    "    E.g., different triangles\n",
    "\n",
    "9. Check the effect of pretraining using available datasets\n",
    "10. Read about one data sample transfer learning \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgrounds_dir = './dataset/backgrounds/'\n",
    "target_dir = './dataset/target/'\n",
    "test_dir = './dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how the target looks like\n",
    "img = cv2.imread(target_dir+'target_shape_marked.png')\n",
    "print('image_shape: ', img.shape)\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#plt the original image\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(121), plt.imshow(img)\n",
    "\n",
    "# Find red pixels - maybe the slowest method :) \n",
    "upper_left_indicator = 0\n",
    "for row_idx in range(img.shape[0]):\n",
    "    for col_idx in range(img.shape[1]):\n",
    "        r = img[row_idx][col_idx][0]\n",
    "        g = img[row_idx][col_idx][1]\n",
    "        b = img[row_idx][col_idx][2]\n",
    "        \n",
    "        if r>100 and g<100 and b<100 and upper_left_indicator == 0:\n",
    "            #upper left row and column idxs\n",
    "            uleft_colrow_idx = (col_idx, row_idx)\n",
    "            upper_left_indicator=1\n",
    "\n",
    "        if upper_left_indicator == 1 and r>100 and g<100 and b<100:\n",
    "\n",
    "            #lower right row and column idxs\n",
    "            lright_colrow_idx = (col_idx, row_idx)\n",
    "        \n",
    "        \n",
    "\n",
    "print(uleft_colrow_idx)\n",
    "print(lright_colrow_idx)\n",
    "img_marked = cv2.circle(img.copy(), uleft_colrow_idx ,50, (0,255,0), 10)\n",
    "img_marked = cv2.circle(img_marked, lright_colrow_idx ,50, (0,255,0), 10)\n",
    "\n",
    "#plot the image with added circles to check if the corner detection is fine\n",
    "plt.subplot(122), plt.imshow(img_marked)\n",
    "plt.show()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how the background files look like\n",
    "fnames = os.listdir(backgrounds_dir)\n",
    "for fname in fnames:\n",
    "    bg_img = cv2.imread(backgrounds_dir+fname, 0)\n",
    "    assert (img.shape[0], img.shape[1]) == (bg_img.shape[0], bg_img.shape[1]) , 'Check dimensions'\n",
    "    \n",
    "print('we are cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping \n",
    "\n",
    "col_ul, row_ul = uleft_colrow_idx\n",
    "col_lr, row_lr = lright_colrow_idx\n",
    "print(row_ul,row_lr) , print(col_ul,col_lr)\n",
    "\n",
    " \n",
    "#object of interest\n",
    "#red rectangle thickness\n",
    "eps = 5\n",
    "ooi = img[row_ul+eps:row_lr-eps,col_ul+eps:col_lr-eps,:].copy()\n",
    "print(ooi.shape)\n",
    "plt.imshow(ooi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c = ooi.shape\n",
    "H,W,C = img.shape\n",
    "print('h/H:{:.2f}, w/W:{:.2f}'.format(h/H, w/W))\n",
    "\n",
    "#convert to gray\n",
    "ooi_g = cv2.cvtColor(ooi, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(ooi_g, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "ia.seed(0)\n",
    "\n",
    "aug = iaa.Affine(\n",
    "    scale={\"x\": (0.1, 1.5), \"y\": (0.1, 1.5)}, \n",
    "    rotate=(-90,+90),\n",
    "    shear=(-10,10),\n",
    "    cval=(255),\n",
    "    fit_output=True)\n",
    "\n",
    "img_batch = [ooi_g, ooi_g,ooi_g,ooi_g,ooi_g,ooi_g,ooi_g,ooi_g,ooi_g]\n",
    "augmented_batch= aug(images = img_batch)\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "for idx, aug_img in enumerate(augmented_batch):\n",
    "    plt.subplot(3,3,idx+1)\n",
    "    plt.imshow(aug_img, cmap='gray')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq_aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flips\n",
    "    \n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.4, 1.1), \"y\": (0.4, 1.1)},\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8),\n",
    "        cval=(255)\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order\n",
    "\n",
    "augmented_batch = seq_aug(images=img_batch)\n",
    "\n",
    "augmented_batch = np.hstack(augmented_batch)\n",
    "print('Augmented_batch_shape: ',augmented_batch.shape)\n",
    "ia.imshow(augmented_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bg_img = cv2.imread(backgrounds_dir+fnames[0],0)\n",
    "t_img = ooi_g.copy()\n",
    "\n",
    "print('bg_img_shape: ', bg_img.shape)\n",
    "print('crop_img_shape: ', ooi_g.shape)\n",
    "\n",
    "SIZE = 256\n",
    "\n",
    "#background and target specs\n",
    "bg_H, bg_W = bg_img.shape\n",
    "h, w = t_img.shape\n",
    "\n",
    "t_dim = (int(SIZE/bg_W*w),int(SIZE/bg_H*h))\n",
    "        \n",
    "bg_img = cv2.resize(bg_img,(SIZE,SIZE), cv2.INTER_AREA)\n",
    "t_img = cv2.resize(t_img,t_dim, cv2.INTER_LANCZOS4)\n",
    "\n",
    "print('bg_img_shape: ', bg_img.shape)\n",
    "print('crop_img_shape: ',t_img.shape)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(121),plt.imshow(bg_img, cmap='gray')\n",
    "\n",
    "plt.subplot(122), plt.imshow(t_img, cmap='gray')\n",
    "plt.plot(70,50,'or')\n",
    "plt.xlim([0,SIZE])\n",
    "plt.ylim([0,SIZE])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do transformations\n",
    "seq_aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flips\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "        translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)},\n",
    "        rotate=(-90, 90),\n",
    "        shear=(-16, 16),\n",
    "        cval=(255),\n",
    "        fit_output=False\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order\n",
    "\n",
    "augmented_t = seq_aug(image = t_img)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121),plt.imshow(t_img, cmap = 'gray')\n",
    "plt.subplot(122), plt.imshow(augmented_t, cmap = 'gray')\n",
    "plt.show()\n",
    "print(augmented_t.shape)\n",
    "\n",
    "#paste on top of the document\n",
    "#get resized specs\n",
    "H_pix, W_pix = bg_img.shape\n",
    "h_pix,w_pix = augmented_t.shape\n",
    "\n",
    "#sample upper left col and row idxs\n",
    "ulcol_idx = np.random.randint(0,(W_pix-w_pix))\n",
    "ulrow_idx = np.random.randint(0,(H_pix-h_pix))\n",
    "\n",
    "crow_idx = ulrow_idx + h_pix//2\n",
    "ccol_idx = ulcol_idx + w_pix//2\n",
    "\n",
    "STRIDE = 32\n",
    "target = np.zeros((SIZE//STRIDE, SIZE//STRIDE), dtype = np.uint8)\n",
    "target[crow_idx//32,ccol_idx//32] = 1\n",
    "#add target on top the background\n",
    "fused_img = bg_img.copy()\n",
    "fused_img[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = augmented_t\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(121),plt.imshow(fused_img, cmap='gray')\n",
    "plt.subplot(122),plt.imshow(target, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIDE = 32\n",
    "N_max = 9\n",
    "N = np.random.randint(1,N_max+1)\n",
    "print('N:', N)\n",
    "target = np.zeros((SIZE//STRIDE, SIZE//STRIDE), dtype = np.uint8)\n",
    "\n",
    "bg_canvas = np.zeros_like(bg_img)\n",
    "\n",
    "for i in range(N):\n",
    "    #we can add resize here\n",
    "    augmented_t = seq_aug(image = t_img)\n",
    "    \n",
    "    #get resized specs\n",
    "    H_pix, W_pix = bg_img.shape\n",
    "    h_pix, w_pix = augmented_t.shape\n",
    "\n",
    "    if i == 0:        \n",
    "        #sample upper left col and row idxs\n",
    "        ulcol_idx = np.random.randint(0,(W_pix-w_pix))\n",
    "        ulrow_idx = np.random.randint(0,(H_pix-h_pix))\n",
    "        \n",
    "        #get the idxs for the center pixel\n",
    "        crow_idx = ulrow_idx + h_pix//2\n",
    "        ccol_idx = ulcol_idx + w_pix//2\n",
    "        \n",
    "        #add target on top the background\n",
    "        fused_img = bg_img.copy()\n",
    "        fused_img[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = augmented_t\n",
    "        \n",
    "        #create the label matrix\n",
    "        target[crow_idx//STRIDE,ccol_idx//STRIDE] = 1\n",
    "        \n",
    "        #add changes to the background canvas\n",
    "        bg_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "    else:  \n",
    "        \n",
    "        dummy_canvas = np.ones_like(bg_canvas)\n",
    "        while (dummy_canvas*bg_canvas).sum() > 0:\n",
    "             #sample upper left col and row idxs\n",
    "            ulcol_idx = np.random.randint(0,(W_pix-w_pix))\n",
    "            ulrow_idx = np.random.randint(0,(H_pix-h_pix))\n",
    "\n",
    "            #get the idxs for the center pixel\n",
    "            crow_idx = ulrow_idx + h_pix//2\n",
    "            ccol_idx = ulcol_idx + w_pix//2\n",
    "\n",
    "            dummy_canvas = np.zeros_like(bg_canvas)\n",
    "            dummy_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "        \n",
    "        #add target on top the background\n",
    "        fused_img[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = augmented_t\n",
    "        \n",
    "        #create the label matrix\n",
    "        target[crow_idx//STRIDE,ccol_idx//STRIDE] = 1\n",
    "        \n",
    "        #add changes to the background canvas\n",
    "        bg_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "        \n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(121),plt.imshow(fused_img)\n",
    "plt.subplot(122),plt.imshow(target)\n",
    "plt.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "class OneShot_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, background_dir = './dataset/backgrounds/', target_dir= './dataset/target/',\n",
    "                target_fname = 'target_shape_marked.png'):\n",
    "\n",
    "        self.background_dir = background_dir\n",
    "        self.target_dir = target_dir\n",
    "        \n",
    "        self.background_fnames = os.listdir(self.background_dir)\n",
    "        self.target_fname = target_fname\n",
    "        \n",
    "        self.idx_range = int(len(self.background_fnames))\n",
    "        self.target_image = self.crop_the_target_shape()\n",
    "        self.augmentation_function = self.sequential_augmentation_function()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.idx_range)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #read a background\n",
    "        bg_path = os.path.join(self.background_dir, self.background_fnames[index])\n",
    "        bg_img = cv2.imread(bg_path,0)\n",
    "        \n",
    "        image_npa, label_npa = self.create_io_arrays(bg_img)\n",
    "        \n",
    "        input_tensor = torch.from_numpy(image_npa).float()\n",
    "        output_tensor = torch.from_numpy(label_npa).float()\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "    \n",
    "    def crop_the_target_shape(self):\n",
    "        # see how the target looks like\n",
    "        img = cv2.cvtColor(cv2.imread(target_dir+'target_shape_marked.png'), cv2.COLOR_BGR2RGB)\n",
    "        print('document_image_shape: ', img.shape)\n",
    "\n",
    "        # Find red pixels - maybe the slowest method :) \n",
    "        upper_left_indicator = 0\n",
    "        for row_idx in range(img.shape[0]):\n",
    "            for col_idx in range(img.shape[1]):\n",
    "                r = img[row_idx][col_idx][0]\n",
    "                g = img[row_idx][col_idx][1]\n",
    "                b = img[row_idx][col_idx][2]\n",
    "\n",
    "                if r>100 and g<100 and b<100 and upper_left_indicator == 0:\n",
    "                    #upper left row and column idxs\n",
    "                    uleft_colrow_idx = (col_idx, row_idx)\n",
    "                    upper_left_indicator=1\n",
    "\n",
    "                if upper_left_indicator == 1 and r>100 and g<100 and b<100:\n",
    "\n",
    "                    #lower right row and column idxs\n",
    "                    lright_colrow_idx = (col_idx, row_idx)\n",
    "\n",
    "\n",
    "        img_marked = cv2.circle(img.copy(), uleft_colrow_idx ,50, (0,255,0), 10)\n",
    "        img_marked = cv2.circle(img_marked, lright_colrow_idx ,50, (0,255,0), 10)\n",
    "\n",
    "        #plot the the original image and the image with added circles \n",
    "        fig = plt.figure(figsize=(16,16))\n",
    "        plt.subplot(121), plt.imshow(img)\n",
    "        plt.subplot(122), plt.imshow(img_marked)\n",
    "        plt.show()\n",
    "\n",
    "        #object of interest\n",
    "        eps = 5 #red rectangle thickness\n",
    "        ooi = img[row_ul+eps:row_lr-eps,col_ul+eps:col_lr-eps,:].copy()\n",
    "\n",
    "        #convert to gray\n",
    "        ooi_g = cv2.cvtColor(ooi, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        h,w,c = ooi.shape\n",
    "        H,W,C = img.shape\n",
    "        \n",
    "        print('object_of_interest_shape: ', ooi.shape)\n",
    "        print('h/H:{:.2f}, w/W:{:.2f}'.format(h/H, w/W))\n",
    "        \n",
    "        h_ratio = h/H\n",
    "        w_ratio = w/W\n",
    "\n",
    "        return ooi_g\n",
    "    \n",
    "    def sequential_augmentation_function(self):\n",
    "        #do transformations\n",
    "        seq_aug = iaa.Sequential([\n",
    "            iaa.Fliplr(0.5), # horizontal flips\n",
    "\n",
    "            # Apply affine transformations to each image.\n",
    "            # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (0.4, 1.1), \"y\": (0.4, 1.1)},\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                rotate=(-25, 25),\n",
    "                shear=(-8, 8),\n",
    "                cval=(255)\n",
    "            )\n",
    "        ], random_order=True) # apply augmenters in random order\n",
    "\n",
    "        return seq_aug\n",
    "    \n",
    "    def create_io_arrays(self, bg_img, N_max=4, i_size=256, stride = 32):\n",
    "        \n",
    "        #background and target specs\n",
    "        bg_H, bg_W = bg_img.shape\n",
    "        h, w = self.target_image.shape\n",
    "        \n",
    "        #respective target object dims\n",
    "        t_dim = (int(i_size/bg_W*w),int(i_size/bg_H*h))\n",
    "        \n",
    "        #resize bg and target object\n",
    "        bg_img = cv2.resize(bg_img,(i_size,i_size), cv2.INTER_LANCZOS4)\n",
    "        t_img = cv2.resize(self.target_image,t_dim, cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        #sample number of objects to dist on the bg\n",
    "        N = np.random.randint(1,N_max+1)\n",
    "        \n",
    "        #initialize the target tensor\n",
    "        target_tensor = np.zeros((i_size//stride, i_size//stride), dtype = np.uint8)\n",
    "        \n",
    "        #canvas to not to put objects on top of eachother\n",
    "        bg_canvas = np.zeros_like(bg_img)\n",
    "\n",
    "        for i in range(N):\n",
    "            \n",
    "            #we can add resize here\n",
    "            augmented_t = self.augmentation_function(image = t_img)\n",
    "\n",
    "            #get resized specs\n",
    "            H_pix, W_pix = bg_img.shape\n",
    "            h_pix, w_pix = augmented_t.shape\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                #sample upper left col and row idxs\n",
    "                ulcol_idx = np.random.randint(0,(W_pix-w_pix))\n",
    "                ulrow_idx = np.random.randint(0,(H_pix-h_pix))\n",
    "\n",
    "                #get the idxs for the center pixel\n",
    "                crow_idx = ulrow_idx + h_pix//2\n",
    "                ccol_idx = ulcol_idx + w_pix//2\n",
    "\n",
    "                #add target on top the background\n",
    "                fused_img = bg_img.copy()\n",
    "                fused_img[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = augmented_t\n",
    "\n",
    "                #create the label matrix\n",
    "                target_tensor[crow_idx//STRIDE,ccol_idx//STRIDE] = 1\n",
    "\n",
    "                #add changes to the background canvas\n",
    "                bg_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "                \n",
    "            else:  \n",
    "\n",
    "                dummy_canvas = np.ones_like(bg_canvas)\n",
    "                while (dummy_canvas*bg_canvas).sum() > 0:\n",
    "                     #sample upper left col and row idxs\n",
    "                    ulcol_idx = np.random.randint(0,(W_pix-w_pix))\n",
    "                    ulrow_idx = np.random.randint(0,(H_pix-h_pix))\n",
    "\n",
    "                    #get the idxs for the center pixel\n",
    "                    crow_idx = ulrow_idx + h_pix//2\n",
    "                    ccol_idx = ulcol_idx + w_pix//2\n",
    "\n",
    "                    dummy_canvas = np.zeros_like(bg_canvas)\n",
    "                    dummy_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "\n",
    "                #add target on top the background\n",
    "                fused_img[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = augmented_t\n",
    "\n",
    "                #create the label matrix\n",
    "                target_tensor[crow_idx//STRIDE,ccol_idx//STRIDE] = 1\n",
    "\n",
    "                #add changes to the background canvas\n",
    "                bg_canvas[ulrow_idx:ulrow_idx+h_pix,ulcol_idx:ulcol_idx+w_pix] = 1\n",
    "        \n",
    "        return fused_img, target_tensor\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_dataset = OneShot_Dataset()\n",
    "print('Dataset_length: ',len(triangle_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 1-2\n",
    "input_tensor, output_tensor = triangle_dataset[0]\n",
    "print(input_tensor.shape, output_tensor.shape)\n",
    "input_npa = input_tensor.numpy()\n",
    "output_npa = output_tensor.numpy()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(121), plt.imshow(input_npa)\n",
    "plt.subplot(122), plt.imshow(output_npa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the neural network class\n",
    "class Mark_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mark_1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            # nn.LeakyReLU()\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0),\n",
    "            # nn.Sigmoid()\n",
    "            # nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.layer1(image)  # (N,\n",
    "        out = self.layer2(out)  # (N,\n",
    "        out = self.layer3(out)  # (N,\n",
    "        out = self.layer4(out)  # (N,\n",
    "        out = self.layer5(out)  # (N,\n",
    "        out = self.layer6(out)  # (N,1,16,16)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device : ', device)\n",
    "\n",
    "model = Mark_1().to(device)\n",
    "print(model)\n",
    "summary(model, input_size=(1,256,256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=triangle_dataset,\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "\n",
    "lmda_noobj = 0.5\n",
    "\n",
    "criterion_MSE = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list=[]\n",
    "epoch_iteration_no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    start_t = time.time()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        images = images.view(-1,1,256,256).float().to(device)\n",
    "        labels = labels.view(-1,1,8,8).float().to(device)\n",
    "#         print('images_shape: ',images.shape)\n",
    "#         print('labels_shape: ',labels.shape)\n",
    "        \n",
    "        targets_flat = labels[:,0,:,:].flatten().to(device)\n",
    "        \n",
    "        if i == 0 and epoch ==0 :\n",
    "            print('i==0,epoch ==0 ',images.shape,labels.shape)\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "#         print('outputs_shape: ',outputs.shape)\n",
    "\n",
    "        #disect the output\n",
    "        outputs_flat = outputs[:,0,:,:].flatten()\n",
    "        \n",
    "        #mask the grid cells that has obj cm\n",
    "        mask_obj = targets_flat>0\n",
    "        mask_noobj = targets_flat==0\n",
    "        \n",
    "        #objectness loss\n",
    "        obj_loss_obj = criterion_MSE(outputs_flat[mask_obj],targets_flat[mask_obj])\n",
    "        obj_loss_noobj = criterion_MSE(outputs_flat[mask_noobj],targets_flat[mask_noobj])\n",
    "        \n",
    "        loss = obj_loss_obj + lmda_noobj*obj_loss_noobj\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        #backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    end_t = time.time()\n",
    "    print('Epoch [{}/{}], loss: {:.12f}, time:{}'.format(epoch+1,num_epochs,loss.item(),end_t-start_t))\n",
    "    print()                \n",
    "    \n",
    "#     if (epoch+1)%save_ckpt_stepn == 0:\n",
    "#         checkp_name = out_dir+'{}_epoch{}'.format(detector_name,(epoch+1)+(epoch_iteration_no)*(num_epochs))\n",
    "#         print('saving model ckpt... \\n',checkp_name)\n",
    "#         torch.save(model.state_dict(),checkp_name)\n",
    "        \n",
    "            \n",
    "epoch_iteration_no +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model w/ all testing data\n",
    "dataset = OneShot_Dataset()\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_npa = np.zeros((len(data_loader),256,256))\n",
    "labels_npa = np.zeros((len(data_loader),8,8))\n",
    "outputs_npa = np.zeros((len(data_loader),8,8))\n",
    "\n",
    "model.eval() #eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    for idx, (images,labels) in enumerate(data_loader):\n",
    "        images = images.view(-1,1,256,256).float().to(device)\n",
    "        targets = labels.view(-1,1,8,8).float().to(device)\n",
    "        #class_preds,x_preds,y_preds = model(images)\n",
    "        out = model(images)\n",
    "        images_npa[idx] = images.squeeze().detach().numpy()\n",
    "        labels_npa[idx] = targets.squeeze().detach().numpy()\n",
    "        outputs_npa[idx] = out.squeeze().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "print('images_npa: ',images_npa.shape)\n",
    "print('labels_npa: ',labels_npa.shape)\n",
    "print('outputs_npa: ',outputs_npa.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= 4\n",
    "\n",
    "row=1\n",
    "col=3\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(row,col,1), plt.imshow(images_npa[idx])\n",
    "plt.subplot(row,col,2), plt.imshow(labels_npa[idx])\n",
    "plt.subplot(row,col,3), plt.imshow(outputs_npa[idx])\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how about testset?\n",
    "fnames = os.listdir(test_dir)\n",
    "ex_img = cv2.imread(test_dir+fnames[0],0)\n",
    "H,W = ex_img.shape\n",
    "\n",
    "print('H,W: ', ex_img.shape)\n",
    "print('Number of test examples: ', len(fnames))\n",
    "\n",
    "#create empth npas\n",
    "test_images = np.zeros((len(fnames),H,W))\n",
    "test_images_resized = np.zeros((len(fnames),256,256))\n",
    "\n",
    "#read and resize all the test files\n",
    "for idx, fname in enumerate(fnames):\n",
    "    img = cv2.imread(test_dir+fname,0)\n",
    "    img_resized = cv2.resize(img,(256,256),cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    test_images[idx] = img\n",
    "    test_images_resized[idx] = img_resized\n",
    "\n",
    "#create the torch tensor to feed\n",
    "test_tensor = torch.from_numpy(test_images_resized)\n",
    "print(test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the resized test document images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_tensor.view(-1,1,256,256).float()).squeeze()\n",
    "    \n",
    "test_outputs = test_outputs.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the outputs\n",
    "test_outputs[test_outputs<0.3]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row=14\n",
    "col=2\n",
    "fig = plt.figure(figsize=(16,128))\n",
    "for i in range(len(fnames)):\n",
    "    plt.subplot(row,col,2*i+1), plt.imshow(test_images_resized[i])\n",
    "    plt.subplot(row,col,2*i+2), plt.imshow(test_outputs[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs_resized = np.zeros_like(test_images)\n",
    "for i in range(11):\n",
    "    test_outputs_resized[i] = cv2.resize(test_outputs[i], (W,H), cv2.INTER_AREA)\n",
    "plt.imshow(test_outputs_resized[1])\n",
    "test_outputs_resized.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_heatmaps = np.zeros_like(test_images)\n",
    "for i in range(11):\n",
    "    final_heatmaps[i] = cv2.addWeighted(test_images[i],0.1,test_outputs_resized[i]*255,0.9,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_idxs = [0,1,2,3,5,7,8,9,10]\n",
    "row=len(selected_idxs)\n",
    "col=2\n",
    "fig = plt.figure(figsize=(16,80))\n",
    "subplot_counter = 1\n",
    "for i in selected_idxs:\n",
    "    \n",
    "    fig.add_subplot(row,col,subplot_counter) \n",
    "    plt.imshow(test_images[i],cmap='gray') \n",
    "    subplot_counter+=1\n",
    "    \n",
    "    fig.add_subplot(row,col,subplot_counter)\n",
    "    plt.imshow(final_heatmaps[i],cmap='gray')\n",
    "    subplot_counter+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
